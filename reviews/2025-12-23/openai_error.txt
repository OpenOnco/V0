Error: RetryError[<Future at 0x10915f4d0 state=finished raised BadRequestError>]

Traceback (most recent call last):
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adickinson/Documents/GitHub/openonco-review/clients/openai_client.py", line 30, in review
    response = client.chat.completions.create(
        model="gpt-5.2",
    ...<10 lines>...
        ]
    )
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<47 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/adickinson/Documents/GitHub/openonco-review/review.py", line 79, in run_single
    result = await client_fn(data_js, prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped
    return await copy(fn, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/Users/adickinson/Documents/GitHub/openonco-review/venv/lib/python3.13/site-packages/tenacity/__init__.py", line 421, in exc_check
    raise retry_exc from fut.exception()
tenacity.RetryError: RetryError[<Future at 0x10915f4d0 state=finished raised BadRequestError>]
